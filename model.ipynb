{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # Trading Strategy Using CSV Data\n",
    "# \n",
    "This notebook demonstrates how to load historical stock data from a CSV file, create lagged return features, train a linear regression model, evaluate its performance, and simulate a simple trading strategy. The approach follows best practices including:\n",
    " \n",
    " - Reading and processing CSV data with proper date parsing and sorting.\n",
    " - Creating lagged features for returns.\n",
    " - Splitting the data in a time-aware manner (80/20 split).\n",
    " - Training a linear regression model.\n",
    " - Computing performance metrics (MAE, R², RMSE) and the annualized Sharpe ratio.\n",
    " - Simulating trading signals and visualizing cumulative returns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error, mean_absolute_percentage_error\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(csv_file):\n",
    "  \"\"\"Loads data from CSV file. Handles datatypes\"\"\"\n",
    "  try:\n",
    "      data = pd.read_csv(csv_file, parse_dates=['Date'], index_col='Date')\n",
    "      data.sort_index(inplace=True)\n",
    "      return data\n",
    "  except FileNotFoundError:\n",
    "      print(f\"Error: File not found at {csv_file}\")\n",
    "      return None\n",
    "  except Exception as e:\n",
    "      print(f\"Error loading data: {e}\")\n",
    "      return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def engineer_features(df):\n",
    "  \"\"\"Engineers features.\"\"\"\n",
    "  try:\n",
    "    # Ensure Date is a datetime type\n",
    "    if 'Date' in df.columns:\n",
    "        df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "    # Convert Volume to numeric (if it contains non-numeric values, convert to NaN)\n",
    "    df['Volume'] = df['Volume'].replace({',':''}, regex=True).astype('float64')\n",
    "\n",
    "    # Basic price transformations\n",
    "    df['Return'] = df['Close'].pct_change()\n",
    "    df['Range'] = (df['High'] - df['Low']) / df['Close']  # Normalized daily range\n",
    "\n",
    "    # Moving Averages\n",
    "    for window in [5, 20, 50, 200]:\n",
    "        df[f'SMA_{window}'] = df['Close'].rolling(window, min_periods=1).mean()\n",
    "        df[f'EMA_{window}'] = df['Close'].ewm(span=window, adjust=False).mean()\n",
    "\n",
    "    # Bollinger Bands\n",
    "    df['BB_MA20'] = df['Close'].rolling(20, min_periods=1).mean()\n",
    "    df['BB_Upper'] = df['BB_MA20'] + 2 * df['Close'].rolling(20).std()\n",
    "    df['BB_Lower'] = df['BB_MA20'] - 2 * df['Close'].rolling(20).std()\n",
    "\n",
    "    # RSI (14-day)\n",
    "    delta = df['Close'].diff()\n",
    "    gain = np.where(delta > 0, delta, 0)\n",
    "    loss = np.where(delta < 0, -delta, 0)\n",
    "    avg_gain = pd.Series(gain).rolling(14, min_periods=1).mean()\n",
    "    avg_loss = pd.Series(loss).rolling(14, min_periods=1).mean()\n",
    "    rs = avg_gain / (avg_loss + 1e-10) #Added 1e-10 to denom\n",
    "    df['RSI_14'] = 100 - (100 / (1 + rs))\n",
    "\n",
    "    # MACD\n",
    "    df['MACD'] = df['Close'].ewm(span=12, adjust=False).mean() - df['Close'].ewm(span=26, adjust=False).mean()\n",
    "    df['MACD_Signal'] = df['MACD'].ewm(span=9, adjust=False).mean()\n",
    "    df['MACD_Hist'] = df['MACD'] - df['MACD_Signal'] #Adding a MACD histogram\n",
    "\n",
    "    # Volatility, Force to float64\n",
    "    for window in [10, 20, 30]:\n",
    "        df[f'Volatility_{window}'] = (df['Return'].rolling(window, min_periods=1).std() * np.sqrt(252)).astype('float64') #Annualize Vol\n",
    "\n",
    "    # On-Balance Volume (OBV)\n",
    "    df['OBV'] = (np.sign(df['Close'].diff()) * df['Volume']).cumsum()\n",
    "\n",
    "    # VWAP\n",
    "    df['VWAP'] = (df['Volume'] * (df['High'] + df['Low'] + df['Close']) / 3).cumsum() / df['Volume'].cumsum()\n",
    "\n",
    "    # Lagged Returns\n",
    "    for lag in [1, 2, 3, 5, 7, 10]:\n",
    "        df[f'Return_Lag_{lag}'] = df['Return'].shift(lag)\n",
    "\n",
    "    # Lagged Volume\n",
    "    df['Volume_Lag_1'] = df['Volume'].shift(1)\n",
    "\n",
    "    # Target (Next day's return)\n",
    "    df['Target'] = df['Close'].shift(-1) - df['Close']\n",
    "\n",
    "    return df\n",
    "  except Exception as e:\n",
    "    print(f\"Error during feature engineering: {e}\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Splitting, Imputation, and Scaling Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_and_scale(train, test, features, scaler_type='StandardScaler'):\n",
    "    \"\"\"Imputes missing values and scales the features.\n",
    "    Returns:\n",
    "        X_train_scaled, X_test_scaled, y_train, y_test, scaler\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Impute missing values in training data using the mean of the training data\n",
    "        train_means = {}  # Store means for each feature from the training set\n",
    "\n",
    "        for feature in features:\n",
    "            train_mean = train[feature].mean()\n",
    "            train_means[feature] = train_mean  # Store the mean\n",
    "            train[feature] = train[feature].fillna(train_mean)\n",
    "            test[feature] = test[feature].fillna(train_mean)  # Use the training mean for test\n",
    "\n",
    "        # Get features before dropping NaN\n",
    "        X_train = train[features].copy()\n",
    "        X_test = test[features].copy()\n",
    "\n",
    "        # Align the targets and remove the data based on available features.\n",
    "        train = train.loc[X_train.index].copy()\n",
    "        test = test.loc[X_test.index].copy()\n",
    "\n",
    "        # Scale, scale based on scaling parameter\n",
    "        if scaler_type == 'StandardScaler':\n",
    "            scaler = StandardScaler()\n",
    "        elif scaler_type == 'MinMaxScaler':\n",
    "            scaler = MinMaxScaler()\n",
    "        elif scaler_type == 'RobustScaler':\n",
    "            scaler = RobustScaler()\n",
    "        else:\n",
    "            raise ValueError(\"Invalid scaler_type. Choose 'StandardScaler', 'MinMaxScaler', or 'RobustScaler'.\")\n",
    "\n",
    "        # Remove NaN values AFTER setting X_train and X_test, to avoid key collisions with y_train\n",
    "        X_train.dropna(inplace=True)\n",
    "        X_test.dropna(inplace=True)\n",
    "\n",
    "        # Align Target variables too after dropping NA in X\n",
    "        y_train = train.loc[X_train.index, 'Target']  # Align indices\n",
    "        y_test = test.loc[X_test.index, 'Target']  # Align indices\n",
    "\n",
    "        # Validate if scaling will break due to small sample size\n",
    "        if len(X_train) < 2 or len(X_test) < 2: # Require two samples to avoid scaler error\n",
    "            print(\"Warning: Too few samples to train model. Please check test and train data set!\")\n",
    "            return None, None, None, None, None\n",
    "\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "        return X_train_scaled, X_test_scaled, y_train, y_test, scaler\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during imputation and scaling: {e}\")\n",
    "        return None, None, None, None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_model(X_train_scaled, X_test_scaled, y_train, y_test):\n",
    "  \"\"\"Trains the linear regression model and calculates/returns the metrics\"\"\"\n",
    "  try:\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "\n",
    "    print(\"\\nModel Performance:\")\n",
    "    print(f\"MAE: {mae:.6f}\")\n",
    "    print(f\"R² Score: {r2:.4f}\")\n",
    "    print(f\"RMSE: {rmse:.4f}\")\n",
    "    print(f\"MAPE: {mape:.4f}\")\n",
    "\n",
    "    return model, y_pred\n",
    "\n",
    "  except Exception as e:\n",
    "    print(f\"Error in model training and evaluation: {e}\")\n",
    "    return None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backtest & Visualisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backtest_and_visualize(data, split_index, y_pred, y_test, X_test, risk_free_rate=0):\n",
    "  \"\"\"Performs backtesting and generates visualizations.\"\"\"\n",
    "  try:\n",
    "      # Get the Date index for the test set\n",
    "      test_dates = data.iloc[split_index:].index\n",
    "\n",
    "      # Recreate the dataframe for the test period, using the raw data before feature engineering\n",
    "      test_data = data.iloc[split_index:].copy()\n",
    "      test_data['Return'] = data['Return'] #Data must be already feature engineered\n",
    "\n",
    "      test_data['Predicted_Return'] = y_pred  # The predicted returns\n",
    "      test_data['Signal'] = np.where(test_data['Predicted_Return'] > 0, 1, -1) #Now it lines up.\n",
    "\n",
    "      # Calculate transaction costs\n",
    "      transaction_cost = 0.001  # Example: 0.1%\n",
    "      test_data[\"Holdings\"] = test_data[\"Signal\"].diff().fillna(0).abs()\n",
    "      test_data[\"Transaction_Cost\"] = transaction_cost * test_data[\"Holdings\"] * test_data[\"Close\"]\n",
    "\n",
    "      test_data['Strategy_Return_No_Cost'] = test_data['Signal'] * y_test - test_data[\"Transaction_Cost\"]  #Now this is correct.\n",
    "      test_data['Market_Return'] = (1 + test_data['Return']).cumprod() #Old return so its B+H over entire dataset\n",
    "      test_data['Strategy_Return_No_Cost'] = (1 + test_data['Strategy_Return_No_Cost']).cumprod() #Strategy return with y_test and no cost\n",
    "\n",
    "      # Calculate Sharpe Ratio (Risk-Free Rate Subtracted)\n",
    "      excess_returns = test_data['Strategy_Return_No_Cost'].pct_change() - risk_free_rate / 252\n",
    "      sharpe_ratio = excess_returns.mean() / excess_returns.std() * np.sqrt(252)\n",
    "\n",
    "      # Calculate Maximum Drawdown\n",
    "      cumulative_returns = test_data['Strategy_Return_No_Cost']\n",
    "      peak = cumulative_returns.cummax()\n",
    "      drawdown = (cumulative_returns - peak) / peak\n",
    "      max_drawdown = drawdown.min()\n",
    "\n",
    "      # Rolling Sharpe Ratio\n",
    "      rolling_sharpe_ratio = excess_returns.rolling(window=252).mean() / excess_returns.rolling(window=252).std() * np.sqrt(252)\n",
    "\n",
    "      print(f\"\\nFinal Strategy Return (No Transaction Costs): {test_data['Strategy_Return_No_Cost'].iloc[-1]:.2f}\")\n",
    "      print(f\"Final Market Return: {test_data['Market_Return'].iloc[-1]:.2f}\")\n",
    "      print(f\"Annualized Sharpe Ratio: {sharpe_ratio:.2f}\")\n",
    "      print(f\"Maximum Drawdown: {max_drawdown:.2%}\")\n",
    "\n",
    "      # Plotting\n",
    "      plt.figure(figsize=(12, 6))\n",
    "      plt.plot(test_data.index, test_data['Market_Return'], label='Buy & Hold')\n",
    "      plt.plot(test_data.index, test_data['Strategy_Return_No_Cost'], label='Strategy (No Transaction Costs)', alpha=0.8)\n",
    "\n",
    "      plt.plot(test_data.index, peak, label='Peak Cumulative Return', linestyle='--', alpha=0.5)  # Show the peak\n",
    "      plt.fill_between(test_data.index, cumulative_returns, peak, where=cumulative_returns < peak, color='red', alpha=0.3, label='Drawdown')\n",
    "\n",
    "      plt.title('Trading Strategy Performance with Drawdown')\n",
    "      plt.ylabel('Cumulative Returns')\n",
    "      plt.legend()\n",
    "      plt.show()\n",
    "\n",
    "      # Plot Rolling Sharpe Ratio\n",
    "      plt.figure(figsize=(12, 6))\n",
    "      plt.plot(test_data.index, rolling_sharpe_ratio, label='Rolling Sharpe Ratio (252 days)')\n",
    "      plt.title('Rolling Sharpe Ratio')\n",
    "      plt.ylabel('Sharpe Ratio')\n",
    "      plt.legend()\n",
    "      plt.show()\n",
    "\n",
    "  except Exception as e:\n",
    "      print(f\"Error during backtesting and visualization: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MaIN Script - move to main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Too few samples to train model. Please check test and train data set!\n",
      "Error in model training and evaluation: This LinearRegression estimator requires y to be passed, but the target y is None.\n",
      "Error during backtesting and visualization: 'Return'\n",
      "Train Dataframe:\n",
      "             Open   High    Low  Close  Adj Close      Volume    Return  \\\n",
      "Date                                                                      \n",
      "2024-03-19  60.24  60.35  60.06  60.23      58.48  15030600.0       NaN   \n",
      "2024-03-20  60.18  60.81  60.16  60.75      58.99  15258800.0  0.008634   \n",
      "2024-03-21  60.56  60.99  60.32  60.47      58.71  13067100.0 -0.004609   \n",
      "2024-03-22  60.52  60.79  60.43  60.49      58.73  11501400.0  0.000331   \n",
      "2024-03-25  60.48  60.71  60.12  60.40      58.65  13144700.0 -0.001488   \n",
      "\n",
      "               Range      SMA_5      EMA_5  ...           OBV       VWAP  \\\n",
      "Date                                        ...                            \n",
      "2024-03-19  0.004815  60.230000  60.230000  ...  1.947988e+08  60.213333   \n",
      "2024-03-20  0.010700  60.490000  60.403333  ...  1.525880e+07  60.394689   \n",
      "2024-03-21  0.011080  60.483333  60.425556  ...  2.191700e+06  60.454558   \n",
      "2024-03-22  0.005951  60.485000  60.447037  ...  1.369310e+07  60.478762   \n",
      "2024-03-25  0.009768  60.468000  60.431358  ...  5.484000e+05  60.465470   \n",
      "\n",
      "            Return_Lag_1  Return_Lag_2  Return_Lag_3  Return_Lag_5  \\\n",
      "Date                                                                 \n",
      "2024-03-19      0.000201      0.000183           NaN      0.000253   \n",
      "2024-03-20      0.000201      0.000183           NaN      0.000253   \n",
      "2024-03-21      0.008634      0.000183           NaN      0.000253   \n",
      "2024-03-22     -0.004609      0.008634           NaN      0.000253   \n",
      "2024-03-25      0.000331     -0.004609      0.008634      0.000253   \n",
      "\n",
      "            Return_Lag_7  Return_Lag_10  Volume_Lag_1  Target  \n",
      "Date                                                           \n",
      "2024-03-19           NaN       0.000306  1.388471e+07    0.52  \n",
      "2024-03-20           NaN       0.000306  1.503060e+07   -0.28  \n",
      "2024-03-21           NaN       0.000306  1.525880e+07    0.02  \n",
      "2024-03-22           NaN       0.000306  1.306710e+07   -0.09  \n",
      "2024-03-25           NaN       0.000306  1.150140e+07    0.14  \n",
      "\n",
      "[5 rows x 36 columns]\n",
      "\n",
      "Test Dataframe:\n",
      "             Open   High    Low  Close  Adj Close      Volume    Return  \\\n",
      "Date                                                                      \n",
      "2025-01-03  61.90  62.08  61.62  61.75      61.30  10403200.0       NaN   \n",
      "2025-01-06  61.50  61.57  60.66  60.81      60.36  17924200.0 -0.015223   \n",
      "2025-01-07  61.11  61.72  60.62  60.84      60.39  17799600.0  0.000493   \n",
      "2025-01-08  60.99  61.77  60.93  61.71      61.26  14412400.0  0.014300   \n",
      "2025-01-10  61.58  61.65  60.73  61.07      60.62  22425000.0 -0.010371   \n",
      "\n",
      "               Range      SMA_5      EMA_5  ...           OBV       VWAP  \\\n",
      "Date                                        ...                            \n",
      "2025-01-03  0.007449  61.750000  61.750000  ...  1.947988e+08  61.816667   \n",
      "2025-01-06  0.014965  61.280000  61.436667  ... -1.792420e+07  61.308356   \n",
      "2025-01-07  0.018080  61.133333  61.237778  ... -1.246000e+05  61.212520   \n",
      "2025-01-08  0.013612  61.277500  61.395185  ...  1.428780e+07  61.273817   \n",
      "2025-01-10  0.015065  61.236000  61.286790  ... -8.137200e+06  61.240350   \n",
      "\n",
      "            Return_Lag_1  Return_Lag_2  Return_Lag_3  Return_Lag_5  \\\n",
      "Date                                                                 \n",
      "2025-01-03      0.000201      0.000183           NaN      0.000253   \n",
      "2025-01-06      0.000201      0.000183           NaN      0.000253   \n",
      "2025-01-07     -0.015223      0.000183           NaN      0.000253   \n",
      "2025-01-08      0.000493     -0.015223           NaN      0.000253   \n",
      "2025-01-10      0.014300      0.000493     -0.015223      0.000253   \n",
      "\n",
      "            Return_Lag_7  Return_Lag_10  Volume_Lag_1  Target  \n",
      "Date                                                           \n",
      "2025-01-03           NaN       0.000306  1.388471e+07   -0.94  \n",
      "2025-01-06           NaN       0.000306  1.040320e+07    0.03  \n",
      "2025-01-07           NaN       0.000306  1.792420e+07    0.87  \n",
      "2025-01-08           NaN       0.000306  1.779960e+07   -0.64  \n",
      "2025-01-10           NaN       0.000306  1.441240e+07    0.58  \n",
      "\n",
      "[5 rows x 36 columns]\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "csv_file = \"data/KO_data.csv\"\n",
    "features = ['Volatility_10', 'Return_Lag_1', 'Return_Lag_2', 'Return_Lag_5', 'Return_Lag_10', 'SMA_5', 'SMA_20', 'EMA_50', 'EMA_200', 'BB_MA20', 'MACD', 'MACD_Hist', 'OBV', 'VWAP', 'Volume_Lag_1', 'RSI_14']\n",
    "scaler_type = 'StandardScaler'\n",
    "risk_free_rate = 0\n",
    "test_size=0.2 #Reduce size of test data\n",
    "\n",
    "# Load data\n",
    "data = load_data(csv_file)\n",
    "if data is None:\n",
    "    exit()\n",
    "\n",
    "# Engineer return in the raw data (used later for B+H)\n",
    "data = engineer_features(data)\n",
    "\n",
    "# Time series split (80% training, 20% testing)\n",
    "split_index = int((1-test_size) * len(data))\n",
    "train_df = data.iloc[:split_index].copy()  # Create a copy\n",
    "test_df = data.iloc[split_index:].copy()  # Create a copy\n",
    "\n",
    "# Feature engineering\n",
    "train_df = engineer_features(train_df)\n",
    "test_df = engineer_features(test_df)\n",
    "\n",
    "if train_df is None or test_df is None:\n",
    "    exit()\n",
    "\n",
    "# Imputation and Scaling\n",
    "X_train_scaled, X_test_scaled, y_train, y_test, scaler = impute_and_scale(train_df, test_df, features, scaler_type)\n",
    "\n",
    "if X_train_scaled is None:\n",
    "    exit()\n",
    "\n",
    "# Model Training and Evaluation\n",
    "model, y_pred = train_and_evaluate_model(X_train_scaled, X_test_scaled, y_train, y_test)\n",
    "\n",
    "if model is None:\n",
    "    exit()\n",
    "\n",
    "# Backtesting and Visualization\n",
    "#Make sure to pass the values for X and Y\n",
    "X_test = test_df[features] #Pull in features from test data, in test dates\n",
    "backtest_and_visualize(data, split_index, y_pred, y_test, X_test, risk_free_rate)\n",
    "\n",
    "print(\"Train Dataframe:\")\n",
    "print(train_df.head())\n",
    "print(\"\\nTest Dataframe:\")\n",
    "print(test_df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
